export const langgraphExamples =
  '<example>\n<task>\nWe need to build out a youtube graph that will parse a video and related data to return info to the user.\n\nI need you to build out the state for me and any related reducers\n\n{\ntitle: string\ndescription: string\nsummary: string\nrelatedUrls: string []\nurl: string\ntranscription: string\nmessages: BaseMessages\nerrors: string[]\n}\n</task>\n\n<output>\nimport { END, START, StateGraph, StateGraphArgs } from "@langchain/langgraph";\nimport { BaseMessage } from "@langchain/core/messages";\nimport { IterableReadableStream } from "@langchain/core/utils/stream";\n\n// Define the YouTube video state interface\ninterface YouTubeVideoState {\n  title: string;\n  description: string;\n  summary: string;\n  relatedUrls: string[];\n  url: string;\n  highlights: string[];\n  transcription: string;\n  /*\n    messages field for potential LLM interactions\n  */\n  messages: BaseMessage[];\n  error: string;\n}\n\nconst stringReducer = (prev: string = "", next?: string): string =>\n  next ?? prev;\nconst arrayReducer = <T>(prev: T[] = [], next?: T[]): T[] => {\n  if (!next) return prev;\n  return [...prev, ...next];\n};\n// Update the graphState with specific reducers for YouTube video state\nconst youtubeGraphState: StateGraphArgs<YouTubeVideoState>["channels"] = {\n  title: {\n    default: () => "",\n    value: stringReducer,\n  },\n  description: {\n    default: () => "",\n    value: stringReducer,\n  },\n  summary: {\n    default: () => "",\n    value: stringReducer,\n  },\n  relatedUrls: {\n    default: () => [],\n    value: (prev: string[] = [], next?: string[]): string[] => {\n      if (!next) return prev;\n      return [...new Set([...prev, ...next])];\n    },\n  },\n  url: {\n    default: () => "https://www.youtube.com/watch?v=dQw4w9WgXcQ",\n    value: stringReducer,\n  },\n  highlights: {\n    default: () => [],\n    value: arrayReducer,\n  },\n  transcription: {\n    default: () => "",\n    value: (prev: string = "", next?: string): string => next ?? prev,\n  },\n  messages: {\n    default: () => [],\n    value: arrayReducer,\n  },\n  error: {\n    default: () => "",\n    value: stringReducer,\n  },\n};\n\n// Define the YouTube graph\nconst youtubeGraphBuilder = new StateGraph<YouTubeVideoState>({\n  channels: youtubeGraphState,\n});\n\nyoutubeGraphBuilder\n  .addNode("getMetadata", async (state) => {\n    console.log("getMetadata", state);\n    // Fetch metadata (title, url, etc.) from YouTube API\n    // Return updated state or catch error to send to handleError node\n    // if error {\n    //   return {\n    //     error: "Error in processing video metadata",\n    // };\n    // }\n    return {\n      title: "Test Title",\n      description: "Test Description",\n      url: "https://www.youtube.com/watch?v=dQw4w9WgXcQ",\n      transcription: "Test Transcription",\n    };\n  })\n  .addNode("getRelatedUrls", async (state) => {\n    console.log("getRelatedUrls", state);\n    // Fetch related URLs\n    // Return updated state\n    return {\n      relatedUrls: ["https://www.youtube.com/watch?v=dQw4w9WgXcQ"],\n    };\n  })\n  .addNode("extractHighlights", async (state) => {\n    console.log("extractHighlights", state);\n    // Extract highlights from video content\n    // Return updated state\n    return {\n      highlights: ["Highlight 1", "Highlight 2"],\n    };\n  })\n  .addNode("generateSummary", async (state) => {\n    console.log("generateSummary", state);\n    // Generate summary of the video\n    // Return updated state\n    return {\n      summary: "Test Summary",\n    };\n  })\n  .addNode("handleMissingTranscription", async (state) => {\n    console.log("Error in processing video metadata");\n    // @TODO: will use a more brute force method by ripping the audio from the video and transcribing ourselves\n    // we still want the meta data from the video though and will need to process in some capacity\n    return {\n      title: "Test Title",\n      description: "Test Description",\n      url: "https://www.youtube.com/watch?v=dQw4w9WgXcQ",\n      transcription: "Brute Forced Test Transcription",\n    };\n  })\n  .addEdge(START, "getMetadata")\n  .addEdge("getRelatedUrls", END)\n  .addEdge("extractHighlights", END)\n  .addEdge("generateSummary", END)\n  .addEdge("handleMissingTranscription", "getRelatedUrls")\n  .addEdge("handleMissingTranscription", "extractHighlights")\n  .addEdge("handleMissingTranscription", "generateSummary")\n  .addConditionalEdges("getMetadata", (state) => {\n    // Example condition: if title is empty, go to error handling node\n    // else move to the next nodes\n    return state.title\n      ? ["getRelatedUrls", "extractHighlights", "generateSummary"]\n      : "handleMissingTranscription";\n  });\nconst youtubeGraph = youtubeGraphBuilder.compile();\n\nexport const processYouTubeVideo = async (\n  videoUrl: string,\n  config?: { configurable: { thread_id: string } }\n): Promise<YouTubeVideoState> => {\n  const initialState: Partial<YouTubeVideoState> = {\n    url: videoUrl,\n  };\n  const finalState = await youtubeGraph.invoke(initialState, config);\n  return finalState;\n};\n\n// Example of how to use streaming\nexport const streamYouTubeVideoProcessing = async (\n  videoUrl: string,\n  config?: { configurable: { thread_id: string } }\n): Promise<IterableReadableStream<YouTubeVideoState>> => {\n  const initialState: Partial<YouTubeVideoState> = {\n    url: videoUrl,\n  };\n  const stream = await youtubeGraph.stream(initialState, {\n    ...config,\n    configurable: { ...config?.configurable, stream_events: true },\n  });\n  return stream;\n};\n</output>\n</example>\n\n<example>\n<task>\nwe need a basic chatbot with checkpointing. Lets have route node that will decide what to do with the users initial query and then it will use the respond node or action node depnding on the route node outcome</task>\n\n<output>"import { END, START, StateGraph } from "@langchain/langgraph";\nimport { BaseMessage, HumanMessage, AIMessage } from "@langchain/core/messages";\nimport { MemorySaver } from "@langchain/langgraph";\n\n// Define the state interface\ninterface ChatbotState {\n  messages: BaseMessage[];\n  current_action: string | null;\n}\n\n// Define the graph builder\nconst graphBuilder = new StateGraph<ChatbotState>({\n  channels: {\n    messages: {\n      default: () => [],\n      reducer: (prev: BaseMessage[], next: BaseMessage[]) => [...prev, ...next],\n    },\n    current_action: {\n      default: () => null,\n      reducer: (_, next) => next,\n    },\n  },\n});\n\n// Add nodes to the graph\ngraphBuilder\n  .addNode("route", (state: ChatbotState) => {\n    console.log("Routing user query");\n    // Mock implementation of routing logic\n    const lastMessage = state.messages[state.messages.length - 1];\n    const content =\n      typeof lastMessage.content === "string"\n        ? lastMessage.content\n        : JSON.stringify(lastMessage.content);\n    if (content.toLowerCase().includes("action")) {\n      return { current_action: "action" };\n    }\n    return { current_action: "respond" };\n  })\n  .addNode("respond", (state: ChatbotState) => {\n    console.log("Generating response");\n    // Mock implementation of response generation\n    return {\n      messages: [new AIMessage("This is a mock response to your query.")],\n    };\n  })\n  .addNode("action", (state: ChatbotState) => {\n    console.log("Performing action");\n    // Mock implementation of action execution\n    return {\n      messages: [new AIMessage("I have performed the requested action.")],\n    };\n  })\n  .addEdge(START, "route")\n  .addConditionalEdges("route", (state) => state.current_action as string, {\n    respond: "respond",\n    action: "action",\n  })\n  .addEdge("respond", END)\n  .addEdge("action", END);\n\n// Compile the graph\nconst graph = graphBuilder.compile({\n  checkpointer: new MemorySaver(),\n});\n\n// Function to process user input\nasync function processChatInput(\n  input: string,\n  threadId: string\n): Promise<ChatbotState> {\n  const config = { configurable: { thread_id: threadId } };\n  const initialState: Partial<ChatbotState> = {\n    messages: [new HumanMessage(input)],\n  };\n\n  try {\n    const finalState = await graph.invoke(initialState, config);\n    return finalState;\n  } catch (error) {\n    console.error("Error processing chat input:", error);\n    throw error;\n  }\n}\n\nexport async function runChatbot() {\n  const threadId = "example-thread";\n  const userInput = "Hello, how are you?";\n\n  try {\n    const result = await processChatInput(userInput, threadId);\n    console.log("Final state:", result);\n  } catch (error) {\n    console.error("Chatbot error:", error);\n  }\n\n  const newInput = "Hello, can you help me with this action?";\n  try {\n    const result = await processChatInput(newInput, threadId);\n    console.log("Final state:", result);\n  } catch (error) {\n    console.error("Chatbot error:", error);\n  }\n}\n"</output>\n</example>"<example>\n<task>\ninterface PlanExecuteState {\n  input: string;\n  plan: string[];\n  pastSteps: [string, string][];\n  response?: string;\n}\n\nconst planExecuteState: StateGraphArgs<PlanExecuteState>["channels"] = {\n  input: {\n    value: (left?: string, right?: string) => right ?? left ?? "",\n  },\n  plan: {\n    value: (x?: string[], y?: string[]) => y ?? x ?? [],\n    default: () => [],\n  },\n  pastSteps: {\n    value: (x: [string, string][], y: [string, string][]) => x.concat(y),\n    default: () => [],\n  },\n  response: {\n    value: (x?: string, y?: string) => y ?? x,\n    default: () => undefined,\n  },\n};\n\nokay, lets create a new graph that builds a planning agent\n</task>\n<output>\nimport { END, START, StateGraph } from "@langchain/langgraph";\nimport { PromptTemplate } from "@langchain/core/prompts";\nimport "dotenv/config";\n\ninterface PlanExecuteState {\n  input: string;\n  plan: string[];\n  pastSteps: [string, string][];\n  response?: string;\n}\n\nconst planExecuteGraph = new StateGraph<PlanExecuteState>({\n  channels: {\n    input: {\n      value: (left?: string, right?: string) => right ?? left ?? "",\n    },\n    plan: {\n      value: (x?: string[], y?: string[]) => y ?? x ?? [],\n      default: () => [],\n    },\n    pastSteps: {\n      value: (x: [string, string][], y: [string, string][]) => x.concat(y),\n      default: () => [],\n    },\n    response: {\n      value: (x?: string, y?: string) => y ?? x,\n      default: () => undefined,\n    },\n  },\n});\n\nexport const planningNode = async (state: PlanExecuteState) => {\n  console.log("Planning for input:", state.input);\n  const mockedPlan = [\n    "1. Choose a date and venue",\n    "2. Create a guest list",\n    "3. Plan decorations and theme",\n    "4. Arrange food and drinks",\n    "5. Organize entertainment",\n  ];\n  return { plan: mockedPlan };\n};\n\nexport const executionNode = async (state: PlanExecuteState) => {\n  const currentStep = state.plan[0];\n  console.log("Executing step:", currentStep);\n  const mockedStepResult = `Completed: ${currentStep}`;\n  return {\n    plan: state.plan.slice(1),\n    pastSteps: [[currentStep, mockedStepResult]],\n  };\n};\n\nexport const responderNode = async (state: PlanExecuteState) => {\n  console.log("Generating response based on executed steps");\n  const mockedResponse = "The surprise birthday party has been successfully planned with all necessary arrangements made.";\n  return { response: mockedResponse };\n};\n\nconst conditionalEdge = (state: PlanExecuteState) => {\n  if (state.plan.length > 0) {\n    console.log("Moving to executor");\n    return "executor";\n  }\n  console.log("Moving to responder");\n  return "responder";\n};\n\nplanExecuteGraph\n  .addNode("planner", planningNode)\n  .addNode("executor", executionNode)\n  .addNode("responder", responderNode)\n  .addEdge(START, "planner")\n  .addEdge("planner", "executor")\n  .addConditionalEdges("executor", conditionalEdge)\n  .addEdge("responder", END);\n\n// Compile the graph\nconst graph = planExecuteGraph.compile();\n\n// Function to process user input\nasync function processPlanExecuteInput(\n  input: string\n): Promise<PlanExecuteState> {\n  const initialState: PlanExecuteState = {\n    input,\n    plan: [],\n    pastSteps: [],\n  };\n\n  try {\n    const finalState = await graph.invoke(initialState);\n    return finalState;\n  } catch (error) {\n    console.error("Error processing input:", error);\n    throw error;\n  }\n}\n\nexport async function runPlanExecuteAgent() {\n  const userInput = "Plan a surprise birthday party for my best friend";\n\n  try {\n    const result = await processPlanExecuteInput(userInput);\n    console.log("Final state:", result);\n    console.log("Response:", result.response);\n  } catch (error) {\n    console.error("Planning agent error:", error);\n  }\n}\n</output></example>"<example>\n<task>we need to build a search graph, this will need to manage state for the search results, the sources that are being searched, key points, related follow up queries, and messages for the user and llm conversation related to the search</task>\n<output>\nimport { END, START, StateGraph, StateGraphArgs } from "@langchain/langgraph";\nimport {\n  BaseMessage,\n  AIMessage,\n  HumanMessage,\n  SystemMessage,\n} from "@langchain/core/messages";\nimport { IterableReadableStream } from "@langchain/core/utils/stream";\n\n// Define the search state interface\ninterface SearchState {\n  query: string;\n  searchResults: string[];\n  sources: string[];\n  keyPoints: string[];\n  relatedQueries: string[];\n  messages: BaseMessage[];\n  error: string;\n}\n\n// Define reducers for each state field\nconst stringReducer = (prev: string = "", next?: string): string =>\n  next ?? prev;\nconst arrayReducer = <T>(prev: T[] = [], next?: T[]): T[] => {\n  if (!next) return prev;\n  return [...new Set([...prev, ...next])];\n};\n\n// Define the graph state with specific reducers\nconst searchGraphState: StateGraphArgs<SearchState>["channels"] = {\n  query: {\n    default: () => "",\n    value: stringReducer,\n  },\n  searchResults: {\n    default: () => [],\n    value: arrayReducer,\n  },\n  sources: {\n    default: () => [],\n    value: arrayReducer,\n  },\n  keyPoints: {\n    default: () => [],\n    value: arrayReducer,\n  },\n  relatedQueries: {\n    default: () => [],\n    value: arrayReducer,\n  },\n  messages: {\n    default: () => [],\n    value: arrayReducer,\n  },\n  error: {\n    default: () => "",\n    value: stringReducer,\n  },\n};\n\n// Create the search graph\nconst searchGraphBuilder = new StateGraph<SearchState>({\n  channels: searchGraphState,\n});\n\nsearchGraphBuilder\n  .addNode("performSearch", async (state: SearchState) => {\n    console.log("Performing search for:", state.query);\n    // Mock implementation: Perform search using the query\n    // Return mock search results and sources\n    return {\n      searchResults: ["Result 1", "Result 2", "Result 3"],\n      sources: ["Source A", "Source B", "Source C"],\n    };\n  })\n  .addNode("extractKeyPoints", async (state: SearchState) => {\n    console.log("Extracting key points from search results");\n    // Mock implementation: Extract key points from search results\n    return {\n      keyPoints: ["Key point 1", "Key point 2", "Key point 3"],\n    };\n  })\n  .addNode("generateRelatedQueries", async (state: SearchState) => {\n    console.log("Generating related queries");\n    // Mock implementation: Generate related queries based on search results and key points\n    return {\n      relatedQueries: ["Related query 1", "Related query 2", "Related query 3"],\n    };\n  })\n  .addNode("generateUserMessage", async (state: SearchState) => {\n    console.log("Generating user message");\n    // Mock implementation: Generate a message for the user summarizing the search results\n    const userMessage = new HumanMessage({\n      content: "Heres a summary of the search results...",\n    });\n    return {\n      messages: [userMessage],\n    };\n  })\n  .addNode("handleLLMResponse", async (state: SearchState) => {\n    console.log("Handling LLM response");\n    // Mock implementation: Process LLM response and update the state\n\n    const llmMessage = new AIMessage({\n      content: "Ive analyzed the search results and heres what I found...",\n    });\n    return {\n      messages: [...state.messages, llmMessage],\n    };\n  })\n  .addNode("handleError", async (state: SearchState) => {\n    console.log("Handling error:", state.error);\n    // Mock implementation: Handle any errors that occurred during the search process\n    const errorMessage = new SystemMessage({\n      content: `An error occurred: ${state.error}`,\n    });\n    return {\n      messages: [...state.messages, errorMessage],\n    };\n  })\n  .addEdge(START, "performSearch")\n  .addEdge("performSearch", "extractKeyPoints")\n  .addEdge("extractKeyPoints", "generateRelatedQueries")\n  .addEdge("generateRelatedQueries", "generateUserMessage")\n  .addEdge("generateUserMessage", "handleLLMResponse")\n  .addEdge("handleLLMResponse", END)\n  .addConditionalEdges("performSearch", (state: SearchState) => {\n    return state.error ? "handleError" : "extractKeyPoints";\n  })\n  .addEdge("handleError", END);\n\nconst searchGraph = searchGraphBuilder.compile();\n\nexport const performSearch = async (\n  query: string,\n  config?: { configurable: { thread_id: string } }\n): Promise<SearchState> => {\n  const initialState: Partial<SearchState> = {\n    query,\n  };\n  const finalState = await searchGraph.invoke(initialState, config);\n  return finalState;\n};\n\nexport const streamSearchProcess = async (\n  query: string,\n  config?: { configurable: { thread_id: string } }\n): Promise<IterableReadableStream<SearchState>> => {\n  const initialState: Partial<SearchState> = {\n    query,\n  };\n  const stream = await searchGraph.stream(initialState, {\n    ...config,\n    configurable: { ...config?.configurable, stream_events: true },\n  });\n  return stream;\n};\n</output>\n</example>\n"';
