import { Anthropic } from "@anthropic-ai/sdk";
import { AIMessage, AIMessageChunk, HumanMessage, isAIMessage, } from "@langchain/core/messages";
import { ChatGenerationChunk, } from "@langchain/core/outputs";
import { getEnvironmentVariable } from "@langchain/core/utils/env";
import { BaseChatModel, } from "@langchain/core/language_models/chat_models";
import { isOpenAITool, } from "@langchain/core/language_models/base";
import { zodToJsonSchema } from "zod-to-json-schema";
import { RunnablePassthrough, RunnableSequence, } from "@langchain/core/runnables";
import { isZodSchema } from "@langchain/core/utils/types";
import { AnthropicToolsOutputParser, extractToolCalls, } from "./output_parsers.js";
import { handleToolChoice, } from "./utils.js";
function _toolsInParams(params) {
    return !!(params.tools && params.tools.length > 0);
}
function _formatImage(imageUrl) {
    const regex = /^data:(image\/.+);base64,(.+)$/;
    const match = imageUrl.match(regex);
    if (match === null) {
        throw new Error([
            "Anthropic only supports base64-encoded images currently.",
            "Example: data:image/png;base64,/9j/4AAQSk...",
        ].join("\n\n"));
    }
    return {
        type: "base64",
        media_type: match[1] ?? "",
        data: match[2] ?? "",
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
    };
}
function anthropicResponseToChatMessages(messages, additionalKwargs) {
    const usage = additionalKwargs.usage;
    const usageMetadata = usage != null
        ? {
            input_tokens: usage.input_tokens ?? 0,
            output_tokens: usage.output_tokens ?? 0,
            total_tokens: (usage.input_tokens ?? 0) + (usage.output_tokens ?? 0),
        }
        : undefined;
    if (messages.length === 1 && messages[0].type === "text") {
        return [
            {
                text: messages[0].text,
                message: new AIMessage({
                    content: messages[0].text,
                    additional_kwargs: additionalKwargs,
                    usage_metadata: usageMetadata,
                    response_metadata: additionalKwargs,
                    id: additionalKwargs.id,
                }),
            },
        ];
    }
    else {
        const toolCalls = extractToolCalls(messages);
        const generations = [
            {
                text: "",
                message: new AIMessage({
                    // eslint-disable-next-line @typescript-eslint/no-explicit-any
                    content: messages,
                    additional_kwargs: additionalKwargs,
                    tool_calls: toolCalls,
                    usage_metadata: usageMetadata,
                    response_metadata: additionalKwargs,
                    id: additionalKwargs.id,
                }),
            },
        ];
        return generations;
    }
}
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function isAnthropicTool(tool) {
    return "input_schema" in tool;
}
function _makeMessageChunkFromAnthropicEvent(data, fields) {
    let usageDataCopy = { ...fields.usageData };
    if (data.type === "message_start") {
        // eslint-disable-next-line @typescript-eslint/no-unused-vars
        const { content, usage, ...additionalKwargs } = data.message;
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const filteredAdditionalKwargs = {};
        for (const [key, value] of Object.entries(additionalKwargs)) {
            if (value !== undefined && value !== null) {
                filteredAdditionalKwargs[key] = value;
            }
        }
        usageDataCopy = usage;
        let usageMetadata;
        if (fields.streamUsage) {
            usageMetadata = {
                input_tokens: usage.input_tokens,
                output_tokens: usage.output_tokens,
                total_tokens: usage.input_tokens + usage.output_tokens,
            };
        }
        return {
            chunk: new AIMessageChunk({
                content: fields.coerceContentToString ? "" : [],
                additional_kwargs: filteredAdditionalKwargs,
                usage_metadata: usageMetadata,
                id: data.message.id,
            }),
            usageData: usageDataCopy,
        };
    }
    else if (data.type === "message_delta") {
        let usageMetadata;
        if (fields.streamUsage) {
            usageMetadata = {
                input_tokens: data.usage.output_tokens,
                output_tokens: 0,
                total_tokens: data.usage.output_tokens,
            };
        }
        if (data?.usage !== undefined) {
            usageDataCopy.output_tokens += data.usage.output_tokens;
        }
        return {
            chunk: new AIMessageChunk({
                content: fields.coerceContentToString ? "" : [],
                additional_kwargs: { ...data.delta },
                usage_metadata: usageMetadata,
            }),
            usageData: usageDataCopy,
        };
    }
    else if (data.type === "content_block_start" &&
        data.content_block.type === "tool_use") {
        return {
            chunk: new AIMessageChunk({
                content: fields.coerceContentToString
                    ? ""
                    : [
                        {
                            index: data.index,
                            ...data.content_block,
                            input: "",
                        },
                    ],
                additional_kwargs: {},
            }),
            usageData: usageDataCopy,
        };
    }
    else if (data.type === "content_block_delta" &&
        data.delta.type === "text_delta") {
        const content = data.delta?.text;
        if (content !== undefined) {
            return {
                chunk: new AIMessageChunk({
                    content: fields.coerceContentToString
                        ? content
                        : [
                            {
                                index: data.index,
                                ...data.delta,
                            },
                        ],
                    additional_kwargs: {},
                }),
                usageData: usageDataCopy,
            };
        }
    }
    else if (data.type === "content_block_delta" &&
        data.delta.type === "input_json_delta") {
        return {
            chunk: new AIMessageChunk({
                content: fields.coerceContentToString
                    ? ""
                    : [
                        {
                            index: data.index,
                            input: data.delta.partial_json,
                            type: data.delta.type,
                        },
                    ],
                additional_kwargs: {},
            }),
            usageData: usageDataCopy,
        };
    }
    else if (data.type === "content_block_start" &&
        data.content_block.type === "text") {
        const content = data.content_block?.text;
        if (content !== undefined) {
            return {
                chunk: new AIMessageChunk({
                    content: fields.coerceContentToString
                        ? content
                        : [
                            {
                                index: data.index,
                                ...data.content_block,
                            },
                        ],
                    additional_kwargs: {},
                }),
                usageData: usageDataCopy,
            };
        }
    }
    return null;
}
function _mergeMessages(messages) {
    // Merge runs of human/tool messages into single human messages with content blocks.
    const merged = [];
    for (const message of messages) {
        if (message._getType() === "tool") {
            if (typeof message.content === "string") {
                merged.push(new HumanMessage({
                    content: [
                        {
                            type: "tool_result",
                            content: message.content,
                            tool_use_id: message.tool_call_id,
                        },
                    ],
                }));
            }
            else {
                merged.push(new HumanMessage({ content: message.content }));
            }
        }
        else {
            const previousMessage = merged[merged.length - 1];
            if (previousMessage?._getType() === "human" &&
                message._getType() === "human") {
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                let combinedContent;
                if (typeof previousMessage.content === "string") {
                    combinedContent = [{ type: "text", text: previousMessage.content }];
                }
                else {
                    combinedContent = previousMessage.content;
                }
                if (typeof message.content === "string") {
                    combinedContent.push({ type: "text", text: message.content });
                }
                else {
                    combinedContent = combinedContent.concat(message.content);
                }
                previousMessage.content = combinedContent;
            }
            else {
                merged.push(message);
            }
        }
    }
    return merged;
}
export function _convertLangChainToolCallToAnthropic(toolCall) {
    if (toolCall.id === undefined) {
        throw new Error(`Anthropic requires all tool calls to have an "id".`);
    }
    return {
        type: "tool_use",
        id: toolCall.id,
        name: toolCall.name,
        input: toolCall.args,
    };
}
function _formatContent(content) {
    const toolTypes = ["tool_use", "tool_result", "input_json_delta"];
    const textTypes = ["text", "text_delta"];
    if (typeof content === "string") {
        return content;
    }
    else {
        const contentBlocks = content.map((contentPart) => {
            if (contentPart.type === "image_url") {
                let source;
                if (typeof contentPart.image_url === "string") {
                    source = _formatImage(contentPart.image_url);
                }
                else {
                    source = _formatImage(contentPart.image_url.url);
                }
                return {
                    type: "image",
                    source,
                };
            }
            else if (textTypes.find((t) => t === contentPart.type) &&
                "text" in contentPart) {
                // Assuming contentPart is of type MessageContentText here
                return {
                    type: "text",
                    text: contentPart.text,
                };
            }
            else if (toolTypes.find((t) => t === contentPart.type)) {
                const contentPartCopy = { ...contentPart };
                if ("index" in contentPartCopy) {
                    // Anthropic does not support passing the index field here, so we remove it.
                    delete contentPartCopy.index;
                }
                if (contentPartCopy.type === "input_json_delta") {
                    // `input_json_delta` type only represents yielding partial tool inputs
                    // and is not a valid type for Anthropic messages.
                    contentPartCopy.type = "tool_use";
                }
                if ("input" in contentPartCopy) {
                    // Anthropic tool use inputs should be valid objects, when applicable.
                    try {
                        contentPartCopy.input = JSON.parse(contentPartCopy.input);
                    }
                    catch {
                        // no-op
                    }
                }
                // TODO: Fix when SDK types are fixed
                return {
                    ...contentPartCopy,
                    // eslint-disable-next-line @typescript-eslint/no-explicit-any
                };
            }
            else {
                throw new Error("Unsupported message content format");
            }
        });
        return contentBlocks;
    }
}
/**
 * Formats messages as a prompt for the model.
 * @param messages The base messages to format as a prompt.
 * @returns The formatted prompt.
 */
function _formatMessagesForAnthropic(messages) {
    const mergedMessages = _mergeMessages(messages);
    let system;
    if (mergedMessages.length > 0 && mergedMessages[0]._getType() === "system") {
        if (typeof messages[0].content !== "string") {
            throw new Error("System message content must be a string.");
        }
        system = messages[0].content;
    }
    const conversationMessages = system !== undefined ? mergedMessages.slice(1) : mergedMessages;
    const formattedMessages = conversationMessages.map((message) => {
        let role;
        if (message._getType() === "human") {
            role = "user";
        }
        else if (message._getType() === "ai") {
            role = "assistant";
        }
        else if (message._getType() === "tool") {
            role = "user";
        }
        else if (message._getType() === "system") {
            throw new Error("System messages are only permitted as the first passed message.");
        }
        else {
            throw new Error(`Message type "${message._getType()}" is not supported.`);
        }
        if (isAIMessage(message) && !!message.tool_calls?.length) {
            if (typeof message.content === "string") {
                if (message.content === "") {
                    return {
                        role,
                        content: message.tool_calls.map(_convertLangChainToolCallToAnthropic),
                    };
                }
                else {
                    return {
                        role,
                        content: [
                            { type: "text", text: message.content },
                            ...message.tool_calls.map(_convertLangChainToolCallToAnthropic),
                        ],
                    };
                }
            }
            else {
                const { content } = message;
                const hasMismatchedToolCalls = !message.tool_calls.every((toolCall) => content.find((contentPart) => (contentPart.type === "tool_use" ||
                    contentPart.type === "input_json_delta") &&
                    contentPart.id === toolCall.id));
                if (hasMismatchedToolCalls) {
                    console.warn(`The "tool_calls" field on a message is only respected if content is a string.`);
                }
                return {
                    role,
                    content: _formatContent(message.content),
                };
            }
        }
        else {
            return {
                role,
                content: _formatContent(message.content),
            };
        }
    });
    return {
        messages: formattedMessages,
        system,
    };
}
function extractToolCallChunk(chunk) {
    let newToolCallChunk;
    // Initial chunk for tool calls from anthropic contains identifying information like ID and name.
    // This chunk does not contain any input JSON.
    const toolUseChunks = Array.isArray(chunk.content)
        ? chunk.content.find((c) => c.type === "tool_use")
        : undefined;
    if (toolUseChunks &&
        "index" in toolUseChunks &&
        "name" in toolUseChunks &&
        "id" in toolUseChunks) {
        newToolCallChunk = {
            args: "",
            id: toolUseChunks.id,
            name: toolUseChunks.name,
            index: toolUseChunks.index,
            type: "tool_call_chunk",
        };
    }
    // Chunks after the initial chunk only contain the index and partial JSON.
    const inputJsonDeltaChunks = Array.isArray(chunk.content)
        ? chunk.content.find((c) => c.type === "input_json_delta")
        : undefined;
    if (inputJsonDeltaChunks &&
        "index" in inputJsonDeltaChunks &&
        "input" in inputJsonDeltaChunks) {
        if (typeof inputJsonDeltaChunks.input === "string") {
            newToolCallChunk = {
                id: inputJsonDeltaChunks.id,
                name: inputJsonDeltaChunks.name,
                args: inputJsonDeltaChunks.input,
                index: inputJsonDeltaChunks.index,
                type: "tool_call_chunk",
            };
        }
        else {
            newToolCallChunk = {
                id: inputJsonDeltaChunks.id,
                name: inputJsonDeltaChunks.name,
                args: JSON.stringify(inputJsonDeltaChunks.input, null, 2),
                index: inputJsonDeltaChunks.index,
                type: "tool_call_chunk",
            };
        }
    }
    return newToolCallChunk;
}
function extractToken(chunk) {
    if (typeof chunk.content === "string") {
        return chunk.content;
    }
    else if (Array.isArray(chunk.content) &&
        chunk.content.length >= 1 &&
        "input" in chunk.content[0]) {
        return typeof chunk.content[0].input === "string"
            ? chunk.content[0].input
            : JSON.stringify(chunk.content[0].input);
    }
    else if (Array.isArray(chunk.content) &&
        chunk.content.length >= 1 &&
        "text" in chunk.content[0]) {
        return chunk.content[0].text;
    }
    return undefined;
}
/**
 * Wrapper around Anthropic large language models.
 *
 * To use you should have the `@anthropic-ai/sdk` package installed, with the
 * `ANTHROPIC_API_KEY` environment variable set.
 *
 * @remarks
 * Any parameters that are valid to be passed to {@link
 * https://console.anthropic.com/docs/api/reference |
 * `anthropic.messages`} can be passed through {@link invocationKwargs},
 * even if not explicitly available on this class.
 * @example
 * ```typescript
 * import { ChatAnthropic } from "@langchain/anthropic";
 *
 * const model = new ChatAnthropic({
 *   temperature: 0.9,
 *   apiKey: 'YOUR-API-KEY',
 * });
 * const res = await model.invoke({ input: 'Hello!' });
 * console.log(res);
 * ```
 */
export class ChatAnthropicMessages extends BaseChatModel {
    static lc_name() {
        return "ChatAnthropic";
    }
    get lc_secrets() {
        return {
            anthropicApiKey: "ANTHROPIC_API_KEY",
            apiKey: "ANTHROPIC_API_KEY",
        };
    }
    get lc_aliases() {
        return {
            modelName: "model",
        };
    }
    constructor(fields) {
        super(fields ?? {});
        Object.defineProperty(this, "lc_serializable", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        Object.defineProperty(this, "anthropicApiKey", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "apiKey", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "apiUrl", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "temperature", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: 1
        });
        Object.defineProperty(this, "topK", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: -1
        });
        Object.defineProperty(this, "topP", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: -1
        });
        Object.defineProperty(this, "maxTokens", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: 2048
        });
        Object.defineProperty(this, "modelName", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "claude-2.1"
        });
        Object.defineProperty(this, "model", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "claude-2.1"
        });
        Object.defineProperty(this, "invocationKwargs", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "stopSequences", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "streaming", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        Object.defineProperty(this, "clientOptions", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        // Used for non-streaming requests
        Object.defineProperty(this, "batchClient", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        // Used for streaming requests
        Object.defineProperty(this, "streamingClient", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "streamUsage", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        this.anthropicApiKey =
            fields?.apiKey ??
                fields?.anthropicApiKey ??
                getEnvironmentVariable("ANTHROPIC_API_KEY");
        if (!this.anthropicApiKey) {
            throw new Error("Anthropic API key not found");
        }
        this.clientOptions = fields?.clientOptions ?? {};
        /** Keep anthropicApiKey for backwards compatibility */
        this.apiKey = this.anthropicApiKey;
        // Support overriding the default API URL (i.e., https://api.anthropic.com)
        this.apiUrl = fields?.anthropicApiUrl;
        /** Keep modelName for backwards compatibility */
        this.modelName = fields?.model ?? fields?.modelName ?? this.model;
        this.model = this.modelName;
        this.invocationKwargs = fields?.invocationKwargs ?? {};
        this.temperature = fields?.temperature ?? this.temperature;
        this.topK = fields?.topK ?? this.topK;
        this.topP = fields?.topP ?? this.topP;
        this.maxTokens =
            fields?.maxTokensToSample ?? fields?.maxTokens ?? this.maxTokens;
        this.stopSequences = fields?.stopSequences ?? this.stopSequences;
        this.streaming = fields?.streaming ?? false;
        this.streamUsage = fields?.streamUsage ?? this.streamUsage;
    }
    getLsParams(options) {
        const params = this.invocationParams(options);
        return {
            ls_provider: "anthropic",
            ls_model_name: this.model,
            ls_model_type: "chat",
            ls_temperature: params.temperature ?? undefined,
            ls_max_tokens: params.max_tokens ?? undefined,
            ls_stop: options.stop,
        };
    }
    /**
     * Formats LangChain StructuredTools to AnthropicTools.
     *
     * @param {ChatAnthropicCallOptions["tools"]} tools The tools to format
     * @returns {AnthropicTool[] | undefined} The formatted tools, or undefined if none are passed.
     * @throws {Error} If a mix of AnthropicTools and StructuredTools are passed.
     */
    formatStructuredToolToAnthropic(tools) {
        if (!tools || !tools.length) {
            return undefined;
        }
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        if (tools.every((tool) => isAnthropicTool(tool))) {
            // If the tool is already an anthropic tool, return it
            return tools;
        }
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        if (tools.every((tool) => isOpenAITool(tool))) {
            // Formatted as OpenAI tool, convert to Anthropic tool
            return tools.map((tc) => ({
                name: tc.function.name,
                description: tc.function.description,
                input_schema: tc.function.parameters,
            }));
        }
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        if (tools.some((tool) => isAnthropicTool(tool))) {
            throw new Error(`Can not pass in a mix of tool schemas to ChatAnthropic`);
        }
        return tools.map((tool) => ({
            name: tool.name,
            description: tool.description,
            input_schema: zodToJsonSchema(tool.schema),
        }));
    }
    bindTools(tools, kwargs) {
        return this.bind({
            tools: this.formatStructuredToolToAnthropic(tools),
            ...kwargs,
        });
    }
    /**
     * Get the parameters used to invoke the model
     */
    invocationParams(options) {
        const tool_choice = handleToolChoice(options?.tool_choice);
        return {
            model: this.model,
            temperature: this.temperature,
            top_k: this.topK,
            top_p: this.topP,
            stop_sequences: options?.stop ?? this.stopSequences,
            stream: this.streaming,
            max_tokens: this.maxTokens,
            tools: this.formatStructuredToolToAnthropic(options?.tools),
            tool_choice,
            ...this.invocationKwargs,
        };
    }
    /** @ignore */
    _identifyingParams() {
        return {
            model_name: this.model,
            ...this.invocationParams(),
        };
    }
    /**
     * Get the identifying parameters for the model
     */
    identifyingParams() {
        return {
            model_name: this.model,
            ...this.invocationParams(),
        };
    }
    async *_streamResponseChunks(messages, options, runManager) {
        const params = this.invocationParams(options);
        const formattedMessages = _formatMessagesForAnthropic(messages);
        const coerceContentToString = !_toolsInParams({
            ...params,
            ...formattedMessages,
            stream: false,
        });
        const stream = await this.createStreamWithRetry({
            ...params,
            ...formattedMessages,
            stream: true,
        });
        let usageData = { input_tokens: 0, output_tokens: 0 };
        for await (const data of stream) {
            if (options.signal?.aborted) {
                stream.controller.abort();
                throw new Error("AbortError: User aborted the request.");
            }
            const result = _makeMessageChunkFromAnthropicEvent(data, {
                streamUsage: !!(this.streamUsage || options.streamUsage),
                coerceContentToString,
                usageData,
            });
            if (!result)
                continue;
            const { chunk, usageData: updatedUsageData } = result;
            usageData = updatedUsageData;
            const newToolCallChunk = extractToolCallChunk(chunk);
            // Extract the text content token for text field and runManager.
            const token = extractToken(chunk);
            yield new ChatGenerationChunk({
                message: new AIMessageChunk({
                    // Just yield chunk as it is and tool_use will be concat by BaseChatModel._generateUncached().
                    content: chunk.content,
                    additional_kwargs: chunk.additional_kwargs,
                    tool_call_chunks: newToolCallChunk ? [newToolCallChunk] : undefined,
                    usage_metadata: chunk.usage_metadata,
                    response_metadata: chunk.response_metadata,
                    id: chunk.id,
                }),
                text: token ?? "",
            });
            if (token) {
                await runManager?.handleLLMNewToken(token);
            }
        }
        let usageMetadata;
        if (this.streamUsage || options.streamUsage) {
            usageMetadata = {
                input_tokens: usageData.input_tokens,
                output_tokens: usageData.output_tokens,
                total_tokens: usageData.input_tokens + usageData.output_tokens,
            };
        }
        yield new ChatGenerationChunk({
            message: new AIMessageChunk({
                content: coerceContentToString ? "" : [],
                additional_kwargs: { usage: usageData },
                usage_metadata: usageMetadata,
            }),
            text: "",
        });
    }
    /** @ignore */
    async _generateNonStreaming(messages, params, requestOptions) {
        const options = params.tools !== undefined
            ? {
                ...requestOptions,
                headers: {
                    ...requestOptions.headers,
                    "anthropic-beta": "tools-2024-04-04",
                },
            }
            : requestOptions;
        const response = await this.completionWithRetry({
            ...params,
            stream: false,
            ..._formatMessagesForAnthropic(messages),
        }, options);
        const { content, ...additionalKwargs } = response;
        const generations = anthropicResponseToChatMessages(content, additionalKwargs);
        // eslint-disable-next-line @typescript-eslint/no-unused-vars
        const { role: _role, type: _type, ...rest } = additionalKwargs;
        return { generations, llmOutput: rest };
    }
    /** @ignore */
    async _generate(messages, options, runManager) {
        if (this.stopSequences && options.stop) {
            throw new Error(`"stopSequence" parameter found in input and default params`);
        }
        const params = this.invocationParams(options);
        if (params.stream) {
            let finalChunk;
            const stream = this._streamResponseChunks(messages, options, runManager);
            for await (const chunk of stream) {
                if (finalChunk === undefined) {
                    finalChunk = chunk;
                }
                else {
                    finalChunk = finalChunk.concat(chunk);
                }
            }
            if (finalChunk === undefined) {
                throw new Error("No chunks returned from Anthropic API.");
            }
            return {
                generations: [
                    {
                        text: finalChunk.text,
                        message: finalChunk.message,
                    },
                ],
            };
        }
        else {
            return this._generateNonStreaming(messages, params, {
                signal: options.signal,
            });
        }
    }
    /**
     * Creates a streaming request with retry.
     * @param request The parameters for creating a completion.
     * @param options
     * @returns A streaming request.
     */
    async createStreamWithRetry(request, options) {
        if (!this.streamingClient) {
            const options_ = this.apiUrl ? { baseURL: this.apiUrl } : undefined;
            this.streamingClient = new Anthropic({
                ...this.clientOptions,
                ...options_,
                apiKey: this.apiKey,
                // Prefer LangChain built-in retries
                maxRetries: 0,
            });
        }
        const makeCompletionRequest = async () => this.streamingClient.messages.create({
            ...request,
            ...this.invocationKwargs,
            stream: true,
        }, options);
        return this.caller.call(makeCompletionRequest);
    }
    /** @ignore */
    async completionWithRetry(request, options) {
        if (!this.batchClient) {
            const options = this.apiUrl ? { baseURL: this.apiUrl } : undefined;
            if (!this.apiKey) {
                throw new Error("Missing Anthropic API key.");
            }
            this.batchClient = new Anthropic({
                ...this.clientOptions,
                ...options,
                apiKey: this.apiKey,
                maxRetries: 0,
            });
        }
        const makeCompletionRequest = async () => this.batchClient.messages.create({
            ...request,
            ...this.invocationKwargs,
        }, options);
        return this.caller.callWithOptions({ signal: options.signal ?? undefined }, makeCompletionRequest);
    }
    _llmType() {
        return "anthropic";
    }
    withStructuredOutput(outputSchema, config) {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const schema = outputSchema;
        const name = config?.name;
        const method = config?.method;
        const includeRaw = config?.includeRaw;
        if (method === "jsonMode") {
            throw new Error(`Anthropic only supports "functionCalling" as a method.`);
        }
        let functionName = name ?? "extract";
        let outputParser;
        let tools;
        if (isZodSchema(schema)) {
            const jsonSchema = zodToJsonSchema(schema);
            tools = [
                {
                    name: functionName,
                    description: jsonSchema.description ?? "A function available to call.",
                    input_schema: jsonSchema,
                },
            ];
            outputParser = new AnthropicToolsOutputParser({
                returnSingle: true,
                keyName: functionName,
                zodSchema: schema,
            });
        }
        else {
            let anthropicTools;
            if (typeof schema.name === "string" &&
                typeof schema.description === "string" &&
                typeof schema.input_schema === "object" &&
                schema.input_schema != null) {
                anthropicTools = schema;
                functionName = schema.name;
            }
            else {
                anthropicTools = {
                    name: functionName,
                    description: schema.description ?? "",
                    input_schema: schema,
                };
            }
            tools = [anthropicTools];
            outputParser = new AnthropicToolsOutputParser({
                returnSingle: true,
                keyName: functionName,
            });
        }
        const llm = this.bind({
            tools,
            tool_choice: {
                type: "tool",
                name: functionName,
            },
        });
        if (!includeRaw) {
            return llm.pipe(outputParser).withConfig({
                runName: "ChatAnthropicStructuredOutput",
            });
        }
        const parserAssign = RunnablePassthrough.assign({
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            parsed: (input, config) => outputParser.invoke(input.raw, config),
        });
        const parserNone = RunnablePassthrough.assign({
            parsed: () => null,
        });
        const parsedWithFallback = parserAssign.withFallbacks({
            fallbacks: [parserNone],
        });
        return RunnableSequence.from([
            {
                raw: llm,
            },
            parsedWithFallback,
        ]).withConfig({
            runName: "StructuredOutputRunnable",
        });
    }
}
export class ChatAnthropic extends ChatAnthropicMessages {
}
